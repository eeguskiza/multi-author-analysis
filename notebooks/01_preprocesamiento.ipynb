{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a489ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar data/raw/{nivel}/{split} → data/processed/{nivel}/{split}/sentences.jsonl\n",
    "# Por línea: doc_id, sent_id, level, split, text_norm, n_tokens, is_boundary (si existe)\n",
    "# Pasos: normalización básica, segmentación en frases, tokenización simple, stemming opcional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c820005",
   "metadata": {},
   "source": [
    "#### ***Imports y config***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4f6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Stemming opcional (NLTK). Si no está, sigue sin stem.\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    STEMMER = SnowballStemmer(\"spanish\")\n",
    "    USE_STEM = True\n",
    "except Exception:\n",
    "    STEMMER = None\n",
    "    USE_STEM = False\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69cbb1",
   "metadata": {},
   "source": [
    "#### ***Rutas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b7e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root():\n",
    "    p = Path.cwd()\n",
    "    for cand in [p, *p.parents]:\n",
    "        if (cand / \"data\" / \"raw\").exists():\n",
    "            return cand\n",
    "    raise FileNotFoundError(\"No encuentro data/raw.\")\n",
    "\n",
    "ROOT = find_root()\n",
    "RAW = ROOT / \"data\" / \"raw\"\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "for d in [PROC, REPORTS]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NIVELES = [\"easy\",\"medium\",\"hard\"]\n",
    "SPLITS = [\"train\",\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d72d9",
   "metadata": {},
   "source": [
    "#### ***Limpieza y Segmentaciion***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4099a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex simples\n",
    "RE_URL = re.compile(r\"https?://\\S+|www\\.\\S+\", re.IGNORECASE)\n",
    "RE_EMAIL = re.compile(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\")\n",
    "RE_NUM = re.compile(r\"\\b\\d+(?:[.,]\\d+)*\\b\")\n",
    "RE_TOKEN = re.compile(r\"[A-Za-zÁÉÍÓÚÜÑáéíóúüñ]+\", re.UNICODE)\n",
    "\n",
    "# Segmentación por fin de frase con excepciones comunes\n",
    "ABREV = {\"sr.\", \"sra.\", \"dr.\", \"dra.\", \"ud.\", \"etc.\", \"p.ej.\", \"ee.uu.\"}\n",
    "SENT_SPLIT = re.compile(r\"(?<=[\\.\\?\\!])\\s+\")\n",
    "\n",
    "def normalizar(text: str) -> str:\n",
    "    t = text.replace(\"\\u00A0\",\" \").strip()\n",
    "    t = RE_URL.sub(\"<URL>\", t)\n",
    "    t = RE_EMAIL.sub(\"<EMAIL>\", t)\n",
    "    t = RE_NUM.sub(\"<NUM>\", t)\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    return t.strip()\n",
    "\n",
    "def segmentar_frases(text: str) -> list[str]:\n",
    "    # Heurística: divide y re-une abreviaturas simples\n",
    "    if not text.strip():\n",
    "        return []\n",
    "    trozos = SENT_SPLIT.split(text.strip())\n",
    "    frases = []\n",
    "    buf = \"\"\n",
    "    for s in trozos:\n",
    "        s2 = s.strip()\n",
    "        if not s2:\n",
    "            continue\n",
    "        if any(s2.endswith(ab) for ab in ABREV):\n",
    "            buf = (buf + \" \" + s2).strip()\n",
    "            continue\n",
    "        if buf:\n",
    "            frases.append((buf + \" \" + s2).strip())\n",
    "            buf = \"\"\n",
    "        else:\n",
    "            frases.append(s2)\n",
    "    if buf:\n",
    "        frases.append(buf)\n",
    "    return frases\n",
    "\n",
    "def tokenizar(text: str) -> list[str]:\n",
    "    toks = RE_TOKEN.findall(text)\n",
    "    if USE_STEM:\n",
    "        toks = [STEMMER.stem(t) for t in toks]\n",
    "    return toks\n",
    "\n",
    "def limpiar_y_tokenizar(frase: str) -> tuple[str,int]:\n",
    "    f = normalizar(frase)\n",
    "    toks = tokenizar(f)\n",
    "    return (\" \".join(toks), len(toks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f072e",
   "metadata": {},
   "source": [
    "#### ***Preprocesado por fichero***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7797f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_id_from_path(fp: Path) -> str:\n",
    "    return fp.stem  # p.ej., problem-123\n",
    "\n",
    "def procesar_txt(fp: Path, level: str, split: str):\n",
    "    out = []\n",
    "    raw = fp.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "    for i, fr in enumerate(segmentar_frases(raw)):\n",
    "        text_norm, n_tok = limpiar_y_tokenizar(fr)\n",
    "        out.append({\n",
    "            \"doc_id\": doc_id_from_path(fp),\n",
    "            \"sent_id\": i,\n",
    "            \"level\": level,\n",
    "            \"split\": split,\n",
    "            \"text_norm\": text_norm,\n",
    "            \"n_tokens\": n_tok,\n",
    "            \"is_boundary\": False  # no viene anotado en .txt\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def procesar_jsonl(fp: Path, level: str, split: str):\n",
    "    out = []\n",
    "    with fp.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            text = str(obj.get(\"text\") or obj.get(\"sentence\") or \"\")\n",
    "            text_norm, n_tok = limpiar_y_tokenizar(text)\n",
    "            is_b = bool(obj.get(\"is_boundary\", False))\n",
    "            out.append({\n",
    "                \"doc_id\": obj.get(\"doc_id\", doc_id_from_path(fp)),\n",
    "                \"sent_id\": obj.get(\"sent_id\", i),\n",
    "                \"level\": level,\n",
    "                \"split\": split,\n",
    "                \"text_norm\": text_norm,\n",
    "                \"n_tokens\": n_tok,\n",
    "                \"is_boundary\": is_b\n",
    "            })\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f027841",
   "metadata": {},
   "source": [
    "#### ***Recorrido por niveles/splits y guardado***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605cdc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Líneas escritas en processed: 208160\n"
     ]
    }
   ],
   "source": [
    "total_lineas = 0\n",
    "for level in NIVELES:\n",
    "    for split in SPLITS:\n",
    "        base = RAW / level / split\n",
    "        if not base.exists():\n",
    "            continue\n",
    "        destino = PROC / level / split\n",
    "        destino.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = destino / \"sentences.jsonl\"\n",
    "\n",
    "        files = list(base.rglob(\"*.txt\")) + list(base.rglob(\"*.jsonl\"))\n",
    "        if not files:\n",
    "            continue\n",
    "\n",
    "        with out_path.open(\"w\", encoding=\"utf-8\") as w:\n",
    "            for fp in files:\n",
    "                if fp.suffix.lower() == \".txt\":\n",
    "                    filas = procesar_txt(fp, level, split)\n",
    "                else:\n",
    "                    filas = procesar_jsonl(fp, level, split)\n",
    "                for row in filas:\n",
    "                    w.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "                total_lineas += len(filas)\n",
    "\n",
    "print(f\"Líneas escritas en processed: {total_lineas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ab84f",
   "metadata": {},
   "source": [
    "#### ***Checks y resumen***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0298c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>level</th>\n",
       "      <th>split</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>is_boundary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>0</td>\n",
       "      <td>easy</td>\n",
       "      <td>train</td>\n",
       "      <td>i learned this about ukraine a while back and i think it was mila kunis who said it and i knew about it since</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>1</td>\n",
       "      <td>easy</td>\n",
       "      <td>train</td>\n",
       "      <td>it s easy for some to make the mistake as back then i had no idea either</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>2</td>\n",
       "      <td>easy</td>\n",
       "      <td>train</td>\n",
       "      <td>but when ppl see others say it the respectfully correct them</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>3</td>\n",
       "      <td>easy</td>\n",
       "      <td>train</td>\n",
       "      <td>it s an offensive way to refer to ukraine and is an old soviet term and minimizes the legitimacy of them being a fre...</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>4</td>\n",
       "      <td>easy</td>\n",
       "      <td>train</td>\n",
       "      <td>similar to how ppl correct others when they use the russian soviet spelling of kyiv and say kiev</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>0</td>\n",
       "      <td>easy</td>\n",
       "      <td>validation</td>\n",
       "      <td>it s bizarre that people think it s controversial</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>1</td>\n",
       "      <td>easy</td>\n",
       "      <td>validation</td>\n",
       "      <td>courts in europe interpreted laws</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>2</td>\n",
       "      <td>easy</td>\n",
       "      <td>validation</td>\n",
       "      <td>the king could put his foot down but the equivalent of that in our system is supposed to be a new law</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>3</td>\n",
       "      <td>easy</td>\n",
       "      <td>validation</td>\n",
       "      <td>if it s a constitutional question then that new law is a constitutional amendment</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>4</td>\n",
       "      <td>easy</td>\n",
       "      <td>validation</td>\n",
       "      <td>i ve yet to read anybody even try to argue that a question of constitutional interpretation doesn t fall under that ...</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>in general be courteous to others</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>debate discuss argue the merits of ideas don t attack people</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>2</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>personal insults shill or troll accusations hate speech any suggestion or support of harm violence or death and othe...</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>for those who have questions regarding any media outlets being posted on this subreddit please click to review our d...</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>4</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>in num the republican primary candidates cut each other to ribbons</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>in general be courteous to others</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>debate discuss argue the merits of ideas don t attack people</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>2</td>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>personal insults shill or troll accusations hate speech any suggestion or support of harm violence or death and othe...</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>for those who have questions regarding any media outlets being posted on this subreddit please click to review our d...</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>4</td>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>if whitmer is able to spin this year s successes into strong action next year she definitely leapfrogs harris as bid...</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>0</td>\n",
       "      <td>hard</td>\n",
       "      <td>train</td>\n",
       "      <td>they don t really even dislike homosexuality as long as they re also committing pedophilia at the same time</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>1</td>\n",
       "      <td>hard</td>\n",
       "      <td>train</td>\n",
       "      <td>god knows the evils of two consenting adults are punishable by death but apparently cool with raped children</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>2</td>\n",
       "      <td>hard</td>\n",
       "      <td>train</td>\n",
       "      <td>the fact that you don t seem to know where your politics end and your religion begins is literally what makes religi...</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>3</td>\n",
       "      <td>hard</td>\n",
       "      <td>train</td>\n",
       "      <td>just because the basics of religion were an outgrowth of human lack of understanding doesn t mean we have to keep them</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>problem-1734</td>\n",
       "      <td>4</td>\n",
       "      <td>hard</td>\n",
       "      <td>train</td>\n",
       "      <td>people don t choose religion out of logic and science atheism agnosticism is basically becoming the norm</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>0</td>\n",
       "      <td>hard</td>\n",
       "      <td>validation</td>\n",
       "      <td>have you seen her linkedin</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>1</td>\n",
       "      <td>hard</td>\n",
       "      <td>validation</td>\n",
       "      <td>have you seen her father do interviews</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>2</td>\n",
       "      <td>hard</td>\n",
       "      <td>validation</td>\n",
       "      <td>which pr firm did she work for it s not even mentioned anywhere</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>3</td>\n",
       "      <td>hard</td>\n",
       "      <td>validation</td>\n",
       "      <td>a few months</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>problem-678</td>\n",
       "      <td>4</td>\n",
       "      <td>hard</td>\n",
       "      <td>validation</td>\n",
       "      <td>this is how what usually works</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc_id  sent_id   level       split  \\\n",
       "0   problem-1734        0    easy       train   \n",
       "1   problem-1734        1    easy       train   \n",
       "2   problem-1734        2    easy       train   \n",
       "3   problem-1734        3    easy       train   \n",
       "4   problem-1734        4    easy       train   \n",
       "5    problem-678        0    easy  validation   \n",
       "6    problem-678        1    easy  validation   \n",
       "7    problem-678        2    easy  validation   \n",
       "8    problem-678        3    easy  validation   \n",
       "9    problem-678        4    easy  validation   \n",
       "10  problem-1734        0  medium       train   \n",
       "11  problem-1734        1  medium       train   \n",
       "12  problem-1734        2  medium       train   \n",
       "13  problem-1734        3  medium       train   \n",
       "14  problem-1734        4  medium       train   \n",
       "15   problem-678        0  medium  validation   \n",
       "16   problem-678        1  medium  validation   \n",
       "17   problem-678        2  medium  validation   \n",
       "18   problem-678        3  medium  validation   \n",
       "19   problem-678        4  medium  validation   \n",
       "20  problem-1734        0    hard       train   \n",
       "21  problem-1734        1    hard       train   \n",
       "22  problem-1734        2    hard       train   \n",
       "23  problem-1734        3    hard       train   \n",
       "24  problem-1734        4    hard       train   \n",
       "25   problem-678        0    hard  validation   \n",
       "26   problem-678        1    hard  validation   \n",
       "27   problem-678        2    hard  validation   \n",
       "28   problem-678        3    hard  validation   \n",
       "29   problem-678        4    hard  validation   \n",
       "\n",
       "                                                                                                                  text_norm  \\\n",
       "0             i learned this about ukraine a while back and i think it was mila kunis who said it and i knew about it since   \n",
       "1                                                  it s easy for some to make the mistake as back then i had no idea either   \n",
       "2                                                              but when ppl see others say it the respectfully correct them   \n",
       "3   it s an offensive way to refer to ukraine and is an old soviet term and minimizes the legitimacy of them being a fre...   \n",
       "4                          similar to how ppl correct others when they use the russian soviet spelling of kyiv and say kiev   \n",
       "5                                                                         it s bizarre that people think it s controversial   \n",
       "6                                                                                         courts in europe interpreted laws   \n",
       "7                     the king could put his foot down but the equivalent of that in our system is supposed to be a new law   \n",
       "8                                         if it s a constitutional question then that new law is a constitutional amendment   \n",
       "9   i ve yet to read anybody even try to argue that a question of constitutional interpretation doesn t fall under that ...   \n",
       "10                                                                                        in general be courteous to others   \n",
       "11                                                             debate discuss argue the merits of ideas don t attack people   \n",
       "12  personal insults shill or troll accusations hate speech any suggestion or support of harm violence or death and othe...   \n",
       "13  for those who have questions regarding any media outlets being posted on this subreddit please click to review our d...   \n",
       "14                                                       in num the republican primary candidates cut each other to ribbons   \n",
       "15                                                                                        in general be courteous to others   \n",
       "16                                                             debate discuss argue the merits of ideas don t attack people   \n",
       "17  personal insults shill or troll accusations hate speech any suggestion or support of harm violence or death and othe...   \n",
       "18  for those who have questions regarding any media outlets being posted on this subreddit please click to review our d...   \n",
       "19  if whitmer is able to spin this year s successes into strong action next year she definitely leapfrogs harris as bid...   \n",
       "20              they don t really even dislike homosexuality as long as they re also committing pedophilia at the same time   \n",
       "21             god knows the evils of two consenting adults are punishable by death but apparently cool with raped children   \n",
       "22  the fact that you don t seem to know where your politics end and your religion begins is literally what makes religi...   \n",
       "23   just because the basics of religion were an outgrowth of human lack of understanding doesn t mean we have to keep them   \n",
       "24                 people don t choose religion out of logic and science atheism agnosticism is basically becoming the norm   \n",
       "25                                                                                               have you seen her linkedin   \n",
       "26                                                                                   have you seen her father do interviews   \n",
       "27                                                          which pr firm did she work for it s not even mentioned anywhere   \n",
       "28                                                                                                             a few months   \n",
       "29                                                                                           this is how what usually works   \n",
       "\n",
       "    n_tokens  is_boundary  \n",
       "0         24        False  \n",
       "1         17        False  \n",
       "2         11        False  \n",
       "3         30        False  \n",
       "4         18        False  \n",
       "5          9        False  \n",
       "6          5        False  \n",
       "7         22        False  \n",
       "8         14        False  \n",
       "9         22        False  \n",
       "10         6        False  \n",
       "11        11        False  \n",
       "12        27        False  \n",
       "13        29        False  \n",
       "14        11        False  \n",
       "15         6        False  \n",
       "16        11        False  \n",
       "17        27        False  \n",
       "18        29        False  \n",
       "19        36        False  \n",
       "20        19        False  \n",
       "21        18        False  \n",
       "22        28        False  \n",
       "23        22        False  \n",
       "24        17        False  \n",
       "25         5        False  \n",
       "26         7        False  \n",
       "27        13        False  \n",
       "28         3        False  \n",
       "29         6        False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga una muestra para verificar\n",
    "muestras = []\n",
    "for level in NIVELES:\n",
    "    for split in SPLITS:\n",
    "        p = PROC / level / split / \"sentences.jsonl\"\n",
    "        if not p.exists():\n",
    "            continue\n",
    "        with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for _ in range(5):\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                muestras.append(json.loads(line))\n",
    "pd.DataFrame(muestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbc4579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>split</th>\n",
       "      <th>n_frases_processed</th>\n",
       "      <th>med_tokens_frase_muestra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>easy</td>\n",
       "      <td>train</td>\n",
       "      <td>52701</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>easy</td>\n",
       "      <td>validation</td>\n",
       "      <td>11146</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>train</td>\n",
       "      <td>55515</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard</td>\n",
       "      <td>validation</td>\n",
       "      <td>11649</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>63386</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medium</td>\n",
       "      <td>validation</td>\n",
       "      <td>13763</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level       split  n_frases_processed  med_tokens_frase_muestra\n",
       "0    easy       train               52701                      13.0\n",
       "1    easy  validation               11146                      13.0\n",
       "4    hard       train               55515                      17.0\n",
       "5    hard  validation               11649                      18.0\n",
       "2  medium       train               63386                      16.0\n",
       "3  medium  validation               13763                      16.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen guardado en reports/\n"
     ]
    }
   ],
   "source": [
    "# Métricas por nivel/split en processed\n",
    "reg = []\n",
    "for level in NIVELES:\n",
    "    for split in SPLITS:\n",
    "        p = PROC / level / split / \"sentences.jsonl\"\n",
    "        if not p.exists():\n",
    "            continue\n",
    "        n_lines = sum(1 for _ in p.open(\"r\", encoding=\"utf-8\"))\n",
    "        # mediana de tokens por frase en una muestra\n",
    "        toks = []\n",
    "        with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 20000:  # límite para rapidez\n",
    "                    break\n",
    "                toks.append(json.loads(line)[\"n_tokens\"])\n",
    "        reg.append({\n",
    "            \"level\": level,\n",
    "            \"split\": split,\n",
    "            \"n_frases_processed\": n_lines,\n",
    "            \"med_tokens_frase_muestra\": float(np.median(toks)) if toks else np.nan\n",
    "        })\n",
    "\n",
    "df_sum = pd.DataFrame(reg).sort_values([\"level\",\"split\"])\n",
    "display(df_sum)\n",
    "\n",
    "# Guarda informe\n",
    "df_sum.to_csv(REPORTS / \"01_processed_resumen.csv\", index=False)\n",
    "(REPORTS / \"01_preprocesamiento_ok.txt\").write_text(\"OK\", encoding=\"utf-8\")\n",
    "print(\"Resumen guardado en reports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace28350",
   "metadata": {},
   "source": [
    "# Informe breve — `01_preprocesamiento.ipynb`\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Convertir RAW en frases normalizadas y reutilizables para EDA y extracción de features.\n",
    "\n",
    "## Pipeline aplicado\n",
    "\n",
    "* Lectura de `data/raw/{easy,medium,hard}/{train,validation}`.\n",
    "* Segmentación por `.?!` con excepciones comunes.\n",
    "* Normalización: minúsculas, `<URL>`, `<EMAIL>`, `<NUM>`, espacios colapsados.\n",
    "* Tokenización alfabética y conteo de tokens.\n",
    "* Stemming español opcional si está disponible.\n",
    "* Escritura en `data/processed/{nivel}/{split}/sentences.jsonl` con:\n",
    "  `doc_id, sent_id, level, split, text_norm, n_tokens, is_boundary`.\n",
    "\n",
    "## Cobertura y tamaño\n",
    "\n",
    "* Líneas totales escritas: **208 160**.\n",
    "\n",
    "|  level |    split   | n_frases_processed |\n",
    "| :----: | :--------: | -----------------: |\n",
    "|  easy  |    train   |             52 701 |\n",
    "|  easy  | validation |             11 146 |\n",
    "| medium |    train   |             63 386 |\n",
    "| medium | validation |             13 763 |\n",
    "|  hard  |    train   |             55 515 |\n",
    "|  hard  | validation |             11 649 |\n",
    "\n",
    "## Estadísticas rápidas\n",
    "\n",
    "Mediana de tokens por frase (muestra):\n",
    "\n",
    "|  level | train | validation |\n",
    "| :----: | ----: | ---------: |\n",
    "|  easy  |  13.0 |       13.0 |\n",
    "| medium |  16.0 |       16.0 |\n",
    "|  hard  |  17.0 |       18.0 |\n",
    "\n",
    "Coherente con el RAW: ~12–13 frases/doc y ~200–230 tokens/doc.\n",
    "\n",
    "## Validaciones\n",
    "\n",
    "* Estructura `processed/{nivel}/{split}` creada con `sentences.jsonl`.\n",
    "* Campos y tipos correctos.\n",
    "* Conteos no nulos en todos los splits.\n",
    "* Resumen guardado en `reports/01_processed_resumen.csv`.\n",
    "\n",
    "## Limitaciones\n",
    "\n",
    "* Segmentación heurística.\n",
    "* La normalización elimina mayúsculas y forma exacta de números.\n",
    "* `is_boundary` solo aparece si venía en origen `.jsonl`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
